#Linux performance metrics
	#Processor metrics
		#CPU utilization
			It describes the overall utilization per processor
			If the CPU utilization exceeds 80% for a sustained period of time,a processor\
				bottleneck is likely
		#User time	
			Depicts the CPU percentage spent on user processes,including nice time.
			High values in user time shows that the system performs actual work.
		#System time
			Depicts the CPU percentage spent on kernel operations including IRQ and softirq time
			High and sustained system time values can point you to bottlenecks in the \
				network and driver stack.
		#Waiting
			Total amount of CPU time spent waiting for an I/O operation to occur.
			A system should not spend too much time waiting for I/O operations.
		#Idle time
			Depicts the CPU percentage the system was idle waiting for tasks.
		#Nice time
			Depicts the CPU percentage spent on re-nicing processes that change the execution \
				order and priority of processes.
		#Load average
			The load average is the rolling average of tht sum of the following:
			 - The number of porcesses in queue waiting to be processesed
			 - The number of processes waiting for uninterruptable task to be completed.
			If processes that request CPU time are blocked (which means that the CPU has no \
				time to process them), the load average will increase. On the other hand,\
				the load will decrease.				
		#Runable processes
			This value depicts the processes that are ready to be executed.
			This value should not exceed 10 times the amount of physical processors for a sustained \
				period of time.
		#Blocked
			Processes that cannot execute while they are waiting for an I/O operation to finish.
			Blocked processes can point you toward an I/O bottleneck.
		#Context switch
			Amount of switches between threads that occur on the system.
			High numbers of context switches in connection with a large number of interrupts can \
				signal driver or application issues.
		#Interrupts
			The interrupts value contains hard interrupts(more adverse effect) and soft interrupts.
			High interrupt values are an indication of a software bottleneck, either in the kernel \
				or a driver.
			Remember that the interrupt value includes the interrupts caused by the CPU clock.
	#Memory metrics
		#Free memory
			The linux kernel allcates most unused memory as file system cache, so subtract the amout\
				of buffers and cache from the used memory to determine(effectively) free memory.
		#Swap usage
			This value depicts the amount of swap space used.
			Values above 200 to 300 pages per second for a sustained period of time express a likely \
				memory bottleneck.
		#Buffer and cache
			Cache allocated as file system and block device cache.
		#Slabs	
			Depicts the kernel usage of memory.
			Note that kernel pages cannot be paged out to disk.
		#Active versus inactive memory
			Provides you with information about the active use of the system memory.
			Inactive memory is a likely candidate to be swapped out to disk by the kswapd daemon.
	#Network interface metrics
		#Packets received and sent
			This metric informs you of the quantity of packets received and sent by a given network\
				interface.
		#Bytes received and sent
			This value depicts the number of bytes received and sent by a given network interface.
		#Collisions per second
			This value provides an indication of the number of collisions that occur on the network\
				that the respective interface is connected to.
			Sustained values of collisions ofter concern a bottleneck in the network infrastructure.
		#Overruns
			Overruns represent the number of times that network interface ran out of buffer space.
			This metric should be used in conjunction with the packets dropped value to identify a \
				possible bottleneck in network buffers or the network queue length.
		#Error
			The number of frames marked as faulty. 
			This is often caused by a network mismatch or a partially broken network cable.
	#Block device metrics
		#Iowait
			Time the CPU spends waiting for an I/O operation to occur.
			High and sustained values most likely indicate an I/O bottleneck.
		#Average queue length
			Amount of outstanding I/O requests.
			In general, a disk queue of 2 to 3 is optimal; higher values might point toward a disk\
				I/O bottleneck.
		#Average wait
			A measurement of the average time in ms it takes for an I/O request to be serviced. The\
				wait time consists of the actual I/O operation and the time it waited in the I/O queue.
		#Transfers per second
			Depicts how many I/O operations per second are performed(read and writes).
			The average tranfer size generally should match with the stripe size used by your disk subsystem.
		#Blocks read/write per second
			This metric depicts the reads and writes per second expressed in blocks of 1024 bytes as of kernel\
				2.6.
		#Kilobytes per second read/write
			Reads and writes from/to the block device in kilobytes represent the amount of actual data \
				transferred to and from the block device.
#Monitoring and benchmark tools			
	#Overview of tool functions
		top			process activity
		vmstat			system acitve, hardware and system information
		uptime,w		average system load
		ps,pstree		displays the processes
		free			memory usage
		iostat			average CPU load, disk activity
		sar			collect and report system activity
		mpstat			multiprocessor usage
		numstat			NUMA-related statistics
		pmap			process memory usage
		netstat			network statistics
		iptraf			real-time network statistics
		tcpdump,ethereal	detailed network traffic analysis
		nmon			collect and report system activity
		strace			system calls
		proc file system	various kernel statistics
		KDE system guard	real-time systems reporting and graphing
		gnome system monitor	real-time systems reporting and graphing

		lmbench			microbenchmark for operating system functions
		iozone			file system benchmark
		netperf 		network performacd benchmark
		netperf			network perfor
        #benchmark tools
          #LMbench
                LMbench is a suite of microbenchmarks that can be used to analyze different operating \
                  system settings. Such as an SELinux enabled system versus a non SELinux system
	  #IOzone
		IOzone is a file sstem benchmark that can be utilized to simulate a wide variety of different\
		        disk access patterns
		Since the configuration possibilities of IOzone are detailed,it is possible to simulate a \
		        targeted workload profile precisely. IOzon writes one or multiple files of varible size using\
		        block sizes
          #netperf
                netperf is a performance benchmark tool that focuses on TCP/IP networking performance.It support\
                        UNIX domain socket and SCTP benchmarking
          #other useful tools
                bonnie          Disk I/O and ifle system benchmark
                bonnie++        Disk I/O and ifle system benchmark
                NetBench        File server benchmark. It runs on Windows
                dbench          File system benchmark. Commonly used for file server benchmark
                iometer         Disk I/O and network benchmark
                ttcp            Simple network benchmark
                nttcp           Simple network benchmark
                iperf           Network benchmark
                ab(Apache Bench)Simple web server benchmark. It comes with Apache HTTP server
                WebStone        used mainly for web server performance benchmarking.
                fsstone,smtpstone
                                Mail server benchmark. They come with Postfix
                nhfsstone       Network File System benchmark. Comes with nfs-utils package
                DirectoryMark   LDAP benchmark
#chapter 3 Aanlyzing performance bottlenecks
        #identifying bottlenecks
          Step:
                1.know your system
                2.back up the system
                3.monitor and analyze the system performance
                4.Narrow down the bottleneck and find its cause
                5.fix the bottleneck cause by trying one change at a time
                6.go back to step 3 until you are satisfied with the performance of the system
          Gathering information
                a complete description of the server
                  -model
                  -age
                  -configuration
                  -peripheral equipment
                  -operating system version and update level
                describle problem
                  -what are the symptoms
                  -describe any error messages
                Who is experiencing the problem?
                  one person, one particular group of people, or?
                  This helps determine whether the problem exists in one particular part of the network, whether\
                        it is application-dependent, and so on
                Can the problem be reproduced
                  All reproducible problems can be solved.
                Document the sequence of actions that are necesary to reproduce the problem
                  -What are the steps to reproduce the problem
                  -Is it an intermittent problem
                  -Does it occur at certain times of the day or certain days of the week
                  -Is it unusual 
                When did the problem start? Was it gradual or did it occur very quickly
                  If the performance issue appeared gradually, then it is likely to be a sizing issue; if it appeared \
                        overnight, thne the problem could be caused by a change made to the server or peripherals
                Have any changes been made to the server(minor or major) or are there any changes in the way clients\
                        are using the server
                Demands could change based on business changes, which could affect demands on a server and network systems
                  >Are there any other servers or hardware components involved
                  >Ary any logs available
                  >Whats is the priority of the problem? When does it have to be fixed
          Analyzing the server's performance '
                #Note: Before taking any troublesshooting actions, back up all data and the configuration information\
                        to prevent a partial or complete loss
                A performance log of the server should be created during its peak time of operation; it will depend on \
                        what services are being provided and on who is using these services. If available, the following\
                        objects should be included:
                  >Processor
                  >System
                  >Server work queues
                  >Memory
                  >Page file
                  >Physical disk
                  >Redirector
                  >Network interface
                Our recommended process, which you can use for your server performance tuning process, is as follow:
                  1.Understand the factors affecting server performance
                  2.Measure the current performance to create a performance baseline to compare with your future \
                        measurements and to identify system bottlenecks
                  3.Use the monitoring tools to identify a performance bottleneck.
                  4.Work with the component that is causing the bottleneck by performing some actions to improve\
                        server performance in response to demands 
                  5.Measure the new performance. This helps you compare performance before and after the tuning steps
                When attempting to fix a performance problem, remember the following:
                  >Application should be compiled with an appropriate optimization level to reduce the path length
                  >Take measuerments before you upgrade or modify anything so that you can tell whether the change\
                        had any effect
                  >Examine the options that involve reconfiguring existing hardware, not just those that involve \
                        adding new hardware
        #CPU bottlenecks
          finding CPU bottlenecks
                uptime  we can get a rough idea of what has been happening in the system for the past 15 minutes
                top
                sar     or $sar -u or $sar -U PROCESSOR_NUMBER
                vmstat
          SMP
                SMP-based systems can present their own set of interesting problems that can be difficult to detect
          Performance tuning options 
                The first step s to ensure that the system performance problem is being caused by the CPU. then a \
                        number of actions can be takenn to improve performance.
                  >Ensure that no unnecessary programs are running in the background by using ps -ef. 
                  >Identify non-critical, CPU-intensive processes by using top and modify their priority using renice
                  >In an SMP-based machine, try using taskset 
